

**K-Means Clustering Project 1**
**Problem Statement**:The main objective is to perform Modeling to the given data. We must try 5 different numbers of clusters based on the elbow curve and for each cluster visualize the clustering results.
**Solution**:We have uploaded a CSV file named Mall_customerrs to the Google Colab and read the given data in the file. K-Means is a distance-based algorithm, this difference of magnitude can create a problem. So let’s first bring all the variables to the same magnitude, we are performing Data Cleaning.  we are checking the basic data of null value or not in some entities like customer ID, annual income, age, and spending score. We Implemented K-Means the objective is to perform K-means clustering on the data and check the clustering metrics (inertia) Now, the objective of K-means is it take some random centroid and calculate the points attached to it and according to that centroid will be shifted. We will have a different cluster which depends on our initializers. Now We have initialized two clusters and pay attention – the initialization is not random here. If clusters are not initialized appropriately, K-Means can result in arbitrarily bad clusters. We have used the k++ initialization which generally produces better results. This is where K-Means++ helps.. Using the K-Means++ algorithm, we optimize the step where we randomly pick the cluster centroid. We are more likely to find a solution that is competitive with the optimal K-Means solution while using the K-Means++ initialization.

**Language Detection and Text Summarization Project 2**
**Problem Statement**:Most advances in NLP are geared toward English as a language. There are over 6000 living languages in the world, with the United Nations recognizing six official languages.
However, NLP techniques are primarily developed in the English language. The following are some of the barriers to NLP proliferation in non-English languages: The amount of research on NLP is heavily skewed toward the English language because it is the most commonly used language for business and academic communication worldwide. English is a high-resource language due to the availability of a large corpus of digital textual data, which is required for training and increasing the accuracy of NLP systems.
**Solution**:Model Architecture consists of an input dataset in 27 different languages, the preprocessing is done on the dataset, and after SVM (support vector machines) is used for the classification of
text. It is observed that the dataset works well for training the model and the model accuracy on the test data was about 85%.
Model=SVM
Train-Test-Split = 70:30
After training the model, the output of the predicted language text is passed to the translate method, it uses Google translator to translate the text in any language to English, and the translated text is used for summarization. In order to perform summarization we used cosine similarity between the word and summarized text with length reduced to the square root of the original text.

**TRANSFER LEARNING FOR MALARIA PARASITE DETECTION project 3**
**Problem Statement**:The project aims to understand the motivation and importance of the deadly disease malaria and the effectiveness of deep learning in detecting malaria. We want to showcase how AI can be useful in assisting with malaria detection, and diagnosis with low-cost effective, and accurate open-source solutions. With the help of Python and deep learning frameworks like TensorFlow, we can build robust, scalable, and effective deep learning solutions. The main advantage of these solutions is being open-source and free, which enables us to build solutions that can be cost-effective and be adopted everywhere and used by everyone with ease. We have analyzed the data of malaria-affected 25000 samples and we used it as training and testing data. And we have built the model to predict the diseased sample with help of the Python and tensor flow.
**Solution**:The main aim of our project is to detect malaria. Below are the requirements to create and train the model
1. Here we are using Jupyter notebook and installing the required Python libraries and
Deep Learning models.
2. Data that contains the images using which we can detect malaria.
3. Flask application installation
The pre-processing techniques used in the research to record the model performance difference. The malaria dataset consists of 27,557 images of which 13,778 are parasitized images and 13,779 are non-infected images. We merged files of both non-infected images and parasitized images and labeled them as parasitized and uninfected for the respective files. The dataset is divided into three sets for training, validation, and testing. The ratio of the train to validation to test is 63:7:30. We choose to take only 63% of the dataset as training to avoid high computational intensity due to the large dataset. The training dataset consists of 63% of the dataset with 8707 healthy images and 8653 malaria images, the validation dataset consists of 7% with 1001 healthy and 928 malaria images, and the testing dataset is 30% of the whole dataset having 4144 and 4124 healthy and malaria images, respectively.
we applied three different models, including basic CNN and two transfer learning models, VGG19 and ResNet50, to detect malaria parasites in blood cell pictures. When the results of each of the models described below are examined, ResNet-50 has the highest accuracy compared to VGG-19 and CNN and exhibits 94 percent correct results.

**Traffic Sign Detection Using CNN project 4**
**Objective**:The objective of this project is to develop a robust and accurate traffic sign detection system using CNNs. The system should be capable of identifying and classifying various types of traffic signs from input images or video streams in real-time.Traffic sign detection is a critical component of autonomous driving systems and advanced driver assistance systems (ADAS). The accurate and real-time detection of traffic signs is essential for ensuring safe and efficient navigation on roads. Convolutional Neural Networks (CNNs) have proven to be highly effective in image recognition tasks, making them a suitable choice for traffic sign detection.
**Solution**:
**Dataset**: Used a comprehensive and well-labeled traffic sign dataset for training and evaluating the CNN model. Ensure that the dataset covers a wide range of traffic sign types, lighting conditions, and perspectives.
**Model Architecture**: Design and implemented a CNN architecture suitable for traffic sign detection.
**Data Preprocessing**: Performed necessary preprocessing steps on the input data, such as resizing, normalization, and augmentation, to enhance the robustness of the model and improve its generalization to different scenarios.
**Training**: Trained the CNN model on the prepared dataset. Fine-tune hyperparameters, such as learning rate and batch size, to achieve optimal performance. Monitored the training process to prevent overfitting and ensure convergence.
**Evaluation Metrics**: we used appropriate evaluation metrics to assess the performance of the model. Common metrics for object detection tasks include precision, recall, F1 score, and mean average precision (mAP).
**Real-time Detection**: Implemented the trained model for real-time traffic sign detection. This involves processing video streams or images in real-time and overlaying bounding boxes and class labels on detected traffic signs.
**User Interface**: Develop a user-friendly interface with the help of Herroku cloud application that displays the real-time detection results to users. This could be a graphical interface showing the camera feed with highlighted traffic signs.

